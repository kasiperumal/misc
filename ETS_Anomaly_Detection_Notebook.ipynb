{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# ETS Anomaly Detection\n", "This notebook uses ETS (Error, Trend, Seasonality) models to detect anomalies in hourly API volume data by identifying points that fall outside the model's confidence intervals."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["!pip install pandas numpy matplotlib statsmodels"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "from statsmodels.tsa.holtwinters import ExponentialSmoothing"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 1: Load the Dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the dataset (replace the path with your file location)\n", "file_path = '/path/to/api_volume_data_with_anomalies_rounded.csv'\n", "data = pd.read_csv(file_path)\n", "\n", "# Convert 'time' to datetime and set as index\n", "data['time'] = pd.to_datetime(data['time'])\n", "data.set_index('time', inplace=True)\n", "\n", "# Preview the data\n", "data.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 2: Initialize and Fit the ETS Model"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Initialize and fit the ETS model\n", "model = ExponentialSmoothing(data['login_count'],\n", "                             seasonal='add',\n", "                             seasonal_periods=24).fit()\n", "\n", "# Generate in-sample predictions\n", "data['forecast'] = model.fittedvalues\n", "data['lower_bound'] = data['forecast'] - 1.96 * model.resid.std()\n", "data['upper_bound'] = data['forecast'] + 1.96 * model.resid.std()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 3: Detect Anomalies"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Detect anomalies: when actual data is outside the prediction confidence interval\n", "data['anomaly'] = (data['login_count'] < data['lower_bound']) | (data['login_count'] > data['upper_bound'])"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 4: Plot the Results with Anomalies Highlighted"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Plot actual data with ETS forecast and confidence intervals\n", "plt.figure(figsize=(14, 7))\n", "plt.plot(data.index, data['login_count'], label='Actual Data', color='blue')\n", "plt.plot(data.index, data['forecast'], label='Forecast', color='green')\n", "plt.fill_between(data.index, data['lower_bound'], data['upper_bound'], color='lightgreen', alpha=0.5)\n", "\n", "# Highlight anomalies\n", "anomalies = data[data['anomaly']]\n", "plt.scatter(anomalies.index, anomalies['login_count'], color='red', label='Anomalies', marker='o')\n", "\n", "plt.xlabel('Date')\n", "plt.ylabel('Login Count')\n", "plt.title('API Volume Anomaly Detection with ETS')\n", "plt.legend()\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Step 5: Save the Results"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Save the data with anomaly indicators\n", "output_path = '/path/to/ets_anomaly_detection_output.csv'\n", "data[['login_count', 'forecast', 'lower_bound', 'upper_bound', 'anomaly']].to_csv(output_path, index=True)\n", "print(f'Results saved to {output_path}')"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 2}